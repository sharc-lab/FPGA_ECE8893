{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import args as cim_args\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "HRS = 148000 # if HRS = LRS*onoff then some issues occur, set this slightly higher\n",
    "LRS = 1000\n",
    "\n",
    "# define arguments for simulation\n",
    "args = cim_args.CIMArgs(\n",
    "    inference=True,\n",
    "    batch_size=1,\n",
    "    mem_values=torch.tensor([HRS, LRS], device='cuda'),\n",
    "    sub_array=[147, 520],\n",
    "    open_rows=21,\n",
    "    adc_precision=5,\n",
    "    weight_precision=8,\n",
    "    input_precision=8\n",
    ")\n",
    "\n",
    "# load inputs\n",
    "input2d = torch.load('../bin/quant_input.bin')\n",
    "weight2d = torch.load('../bin/quant_weight.bin')\n",
    "\n",
    "# store original weight shape\n",
    "weight2d_shape = weight2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.adc_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 81,  81,  81,  ..., 133, 121, 124],\n",
       "        [ 81,  81,  81,  ..., 124, 134, 128],\n",
       "        [ 81,  81,  81,  ..., 128, 134, 112],\n",
       "        ...,\n",
       "        [101, 114, 113,  ...,  81,  81,  81],\n",
       "        [113,  94,  46,  ...,  81,  81,  81],\n",
       "        [ 81,  81,  81,  ...,  81,  81,  81]], device='cuda:0',\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('../csv/input2d.csv', input2d.cpu().numpy(), delimiter=',', fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[126, 123, 129,  ..., 123, 127, 127],\n",
       "        [127, 130, 125,  ..., 127, 127, 127],\n",
       "        [130, 129, 126,  ..., 138, 126, 127],\n",
       "        ...,\n",
       "        [105, 133, 116,  ..., 144, 120, 127],\n",
       "        [143, 124, 131,  ..., 153, 134, 127],\n",
       "        [124, 119, 132,  ..., 121, 134, 127]], device='cuda:0',\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight2d"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breakdown of simulate_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert weights to eNVM cell values\n",
    "\n",
    "# convert to binary\n",
    "base = len(args.mem_values)\n",
    "bits = args.weight_precision\n",
    "\n",
    "rows, cols = weight2d.shape\n",
    "dec_matrix = weight2d.flatten().reshape(-1,1).int()\n",
    "\n",
    "max_val = 2**bits\n",
    "num_digits = math.ceil(math.log(max_val, base))\n",
    "\n",
    "binary_weights = base**torch.arange(num_digits, device='cuda').flip(0)\n",
    "\n",
    "binary_weights = dec_matrix // binary_weights % base\n",
    "\n",
    "binary_weights = binary_weights.reshape(rows, num_digits*cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 1,  ..., 1, 1, 1],\n",
       "        [0, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 0, 0,  ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [0, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 1, 1,  ..., 1, 1, 1]], device='cuda:0')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert binary weights to resistances\n",
    "weights = args.mem_values[binary_weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[148000,   1000,   1000,  ...,   1000,   1000,   1000],\n",
       "        [148000,   1000,   1000,  ...,   1000,   1000,   1000],\n",
       "        [  1000, 148000, 148000,  ...,   1000,   1000,   1000],\n",
       "        ...,\n",
       "        [148000,   1000,   1000,  ...,   1000,   1000,   1000],\n",
       "        [  1000, 148000, 148000,  ...,   1000,   1000,   1000],\n",
       "        [148000,   1000,   1000,  ...,   1000,   1000,   1000]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert resistances to conductances\n",
    "np.savetxt('../csv/weight2d.csv', weights.cpu().numpy(), delimiter=',', fmt='%d')\n",
    "weights = 1 / weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for calculating the optimal value of resistive divider\n",
    "def R_opt(R1, R2):\n",
    "    return (R1-R2*math.sqrt(R1/R2))/(math.sqrt(R1/R2)-1)\n",
    "\n",
    "# calculate reference voltages\n",
    "num_refs = (2**args.adc_precision)\n",
    "x = torch.arange(num_refs, device='cuda') + 1\n",
    "\n",
    "vdd = args.vdd\n",
    "LRS = args.mem_values[-1]\n",
    "HRS = args.mem_values[0]\n",
    "\n",
    "r_max = 1/(x/LRS)\n",
    "r_min = 1/((args.open_rows-(x-1))/HRS + (x-1)/LRS)\n",
    "\n",
    "# calculate optimal value of resistive divider for largest sense margins\n",
    "res_divider = (R_opt(r_min[0], r_max[0]) + R_opt(r_min[args.open_rows-1], r_max[args.open_rows-1]))/2\n",
    "\n",
    "v_max = vdd*(r_max/(res_divider + r_max))\n",
    "v_min = vdd*(r_min/(res_divider + r_min))\n",
    "\n",
    "v_ref = (v_min+v_max)/2\n",
    "\n",
    "# update args\n",
    "args.res_divider = res_divider\n",
    "args.v_ref = v_ref\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1351.7611, device='cuda:0')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_divider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('../csv/v_ref.csv', v_ref.cpu().numpy(), delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "        19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v_ref.cpu().numpy().tofile('../bin/v_ref_32_c.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(999.9999, device='cuda:0')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_max[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(47.6190, device='cuda:0')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_max[args.open_rows-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7047.6187, device='cuda:0')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_min[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(49.9831, device='cuda:0')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_min[args.open_rows-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1351.7611, device='cuda:0')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_divider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4252, 0.2700, 0.1978, 0.1561, 0.1289, 0.1098, 0.0956, 0.0846, 0.0760,\n",
       "        0.0689, 0.0630, 0.0581, 0.0538, 0.0502, 0.0470, 0.0442, 0.0417, 0.0395,\n",
       "        0.0375, 0.0357, 0.0340, 0.0325, 0.0312, 0.0299, 0.0287, 0.0277, 0.0267,\n",
       "        0.0257, 0.0249, 0.0241, 0.0233, 0.0226], device='cuda:0')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8391, 0.3946, 0.2579, 0.1916, 0.1524, 0.1265, 0.1081, 0.0944, 0.0838,\n",
       "        0.0753, 0.0684, 0.0627, 0.0578, 0.0536, 0.0500, 0.0469, 0.0441, 0.0416,\n",
       "        0.0394, 0.0375, 0.0357, 0.0340, 0.0325, 0.0312, 0.0299, 0.0288, 0.0277,\n",
       "        0.0267, 0.0258, 0.0249, 0.0241, 0.0234], device='cuda:0')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6321, 0.3323, 0.2279, 0.1738, 0.1406, 0.1181, 0.1019, 0.0895, 0.0799,\n",
       "        0.0721, 0.0657, 0.0604, 0.0558, 0.0519, 0.0485, 0.0455, 0.0429, 0.0406,\n",
       "        0.0385, 0.0366, 0.0348, 0.0333, 0.0319, 0.0305, 0.0293, 0.0282, 0.0272,\n",
       "        0.0262, 0.0253, 0.0245, 0.0237, 0.0230], device='cuda:0')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define ADC_output function\n",
    "def ADC_output(args, inputs, weights):\n",
    "    \n",
    "    inputs = inputs.to(dtype=torch.float32)\n",
    "    weights = weights.to(dtype=torch.float32)\n",
    "\n",
    "    # calculate the equivalent conductance of each column\n",
    "    equiv_cond = torch.matmul(inputs, weights)\n",
    "\n",
    "    vdd = args.vdd\n",
    "\n",
    "    # calculate the voltage of each column\n",
    "    BL_voltages = torch.div(vdd, 1 + torch.mul(equiv_cond, args.res_divider))\n",
    "\n",
    "    # sense the voltage of each column\n",
    "    num_refs = 2**args.adc_precision\n",
    "\n",
    "    ADC_output = num_refs - torch.bucketize(BL_voltages, args.v_ref.flip(0), out_int32=True, right=True)\n",
    "\n",
    "    return ADC_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "tensor(59., device='cuda:0')\n",
      "tensor(15., device='cuda:0')\n",
      "tensor(17., device='cuda:0')\n",
      "tensor(18., device='cuda:0')\n",
      "tensor(12, device='cuda:0', dtype=torch.int32)\n",
      "tensor(16, device='cuda:0', dtype=torch.int32)\n",
      "tensor(5, device='cuda:0', dtype=torch.int32)\n",
      "tensor(9, device='cuda:0', dtype=torch.int32)\n",
      "tensor(8, device='cuda:0', dtype=torch.int32)\n",
      "tensor(5, device='cuda:0', dtype=torch.int32)\n",
      "tensor(5, device='cuda:0', dtype=torch.int32)\n",
      "tensor(60., device='cuda:0')\n",
      "tensor(19., device='cuda:0')\n",
      "tensor(53., device='cuda:0')\n",
      "tensor(2., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "ADC_out = torch.zeros((input2d.shape[0], weights.shape[1]), device='cuda')\n",
    "Psum = torch.zeros_like(ADC_out)\n",
    "\n",
    "# divide the weight matrix into partitions\n",
    "num_partitions = math.ceil(weights.shape[0]/args.open_rows)\n",
    "print(num_partitions) \n",
    "\n",
    "# calculate ADC outputs for each bit of the input\n",
    "for i in range(args.input_precision):\n",
    "    mask = 2**i\n",
    "    input = (input2d & mask) >> i\n",
    "\n",
    "    # if i == 4:\n",
    "    #     print(input[0][24*8])\n",
    "\n",
    "    # calculate partial sum for each partition\n",
    "    Psum[:,:] = 0\n",
    "\n",
    "    for part in range(num_partitions):  \n",
    "\n",
    "        start_row = part*args.open_rows\n",
    "        end_row   = start_row + args.open_rows\n",
    "\n",
    "        # get digital outputs from the ADCs\n",
    "        out = ADC_output(args, input[:, start_row:end_row], weights[start_row:end_row, :])\n",
    "        # print(out[0][24*8])\n",
    "\n",
    "        # add partition output to total output of the sub array\n",
    "        Psum += out\n",
    "\n",
    "    \n",
    "    # scale partial sum for input bit significance\n",
    "    Psum *= mask\n",
    "\n",
    "    # add partition output to total output of the sub array\n",
    "    ADC_out += Psum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mask to account for the weight precision\n",
    "max_val = 2**args.weight_precision\n",
    "base = len(args.mem_values)\n",
    "cols_per_weight = math.ceil(math.log(max_val, base))\n",
    "weights_mask = base**torch.arange(cols_per_weight, device='cuda').flip(0)\n",
    "\n",
    "# split output into groups of each dot product\n",
    "ADC_out = ADC_out.reshape(ADC_out.shape[0], int(ADC_out.shape[1]/cols_per_weight), cols_per_weight)\n",
    "\n",
    "# multiply each dot product by the weight mask\n",
    "ADC_out *= weights_mask\n",
    "\n",
    "# add output bits together and accumulate total output\n",
    "output = ADC_out.sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1572897., device='cuda:0')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare with correct output\n",
    "correct_output = torch.load('../bin/correct_output.bin')\n",
    "\n",
    "output[0][24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1566390., 1518860., 1567446., 1592368., 1574229., 1565001., 1567719.,\n",
       "        1560396., 1484889., 1558856., 1550843., 1561893., 1472448., 1633787.,\n",
       "        1560208., 1552162., 1564499., 1555341., 1561253., 1737761., 1537762.,\n",
       "        1555929., 1561823., 1550852., 1614412., 1547837., 1555974., 1594043.,\n",
       "        1562478., 1257210., 1557829., 1549665., 1578656., 1571097., 1549261.,\n",
       "        1591087., 1548641., 1552569., 1556776., 1652367., 1567072., 1537333.,\n",
       "        1564913., 1552418., 1565795., 1556537., 1560376., 1568563., 1557226.,\n",
       "        1557383., 1560979., 1557701., 1497948., 1562933., 1528514., 1558376.,\n",
       "        1523191., 1562043., 1561805., 1588803., 1561691., 1554277., 1566757.,\n",
       "        1564184., 1560957.], device='cuda:0')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_output[1][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct_output = correct_output.cpu().numpy()\n",
    "np.savetxt('../csv/correct_output.csv', correct_output.cpu().numpy(), delimiter=',', fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(output, correct_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
